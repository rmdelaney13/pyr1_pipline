#!/usr/bin/env python
"""
Sequence-CSV-based docking with H-bond geometry constraints.

Threads protein sequences from a CSV file onto specified positions and performs
docking with the same rigorous water H-bond geometry filters as the glycine-shaved pipeline.

CSV Format:
    name,signature
    seq1,QILMVAGDHVXXXXXX
    seq2,AILVMQGDHVYYYYYY

Usage:
    # Single sequence (row 0)
    python grade_conformers_sequence_csv_docking_multiple_slurm.py config.txt 0

    # SLURM array (one job per sequence)
    sbatch --array=0-N grade_conformers_sequence_csv_docking_multiple_slurm.py config.txt $SLURM_ARRAY_TASK_ID
"""

import argparse
import json
import os
import shutil
import sys
import time
import logging

import pandas as pd
from configparser import ConfigParser

import docking_pipeline_utils as dpu

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)


def _cfg_clean(raw):
    if raw is None:
        return ""
    return str(raw).split("#", 1)[0].strip()


def _cfg_float(section, key, default):
    raw = section.get(key, None)
    cleaned = _cfg_clean(raw)
    if cleaned == "":
        cleaned = str(default)
    return float(cleaned)


def _cfg_int(section, key, default):
    raw = section.get(key, None)
    cleaned = _cfg_clean(raw)
    if cleaned == "":
        cleaned = str(default)
    return int(float(cleaned))


def _cfg_bool(section, key, default):
    raw = section.get(key, None)
    cleaned = _cfg_clean(raw).lower()
    if cleaned == "":
        return bool(default)
    return cleaned in {"1", "true", "yes", "on"}


def load_sequence_from_csv(csv_path, array_index):
    """
    Load a specific sequence from CSV by array index.

    Returns:
        tuple: (sequence_name, signature_string, positions_list)
    """
    df = pd.read_csv(csv_path)

    if array_index >= len(df):
        raise ValueError(
            f"Array index {array_index} out of range. CSV has {len(df)} sequences (0-{len(df)-1})"
        )

    row = df.iloc[array_index]
    seq_name = str(row["name"]).strip()
    signature = str(row["signature"]).strip()

    logger.info(f"Loaded sequence {array_index}: name='{seq_name}', signature='{signature}'")
    return seq_name, signature


def validate_signature(signature, positions):
    """Validate that signature length matches positions."""
    if len(signature) != len(positions):
        raise ValueError(
            f"Signature length ({len(signature)}) does not match positions count ({len(positions)}). "
            f"Expected {len(positions)} amino acids."
        )

    valid_aa = set("ACDEFGHIKLMNPQRSTVWY")
    for i, aa in enumerate(signature):
        if aa.upper() not in valid_aa:
            raise ValueError(
                f"Invalid amino acid '{aa}' at position {i} in signature. "
                f"Must be one of: {' '.join(sorted(valid_aa))}"
            )


def csv_to_df_pkl(csv_file_name, pkl_file_name, auto, path_to_conformers, pose, target_res, lig_res_num):
    """
    Converts CSV generated by create_table.py into a DataFrame expected by conformer_prep.
    """
    df = pd.read_csv(csv_file_name, index_col=False)
    if pkl_file_name is None:
        pkl_file_name = f"{csv_file_name[:-4]}.pkl"

    df["Molecule File Stem"] = df["Molecule ID"].apply(lambda name: f"{name}/{name}")
    df["Conformer Range"] = df["Conformer Range"].apply(lambda name: tuple(name.split("_")[:2]))

    if auto:
        print("Auto Generating Alignments")
        for i, row in df.iterrows():
            print(i, end=" ")
            lig = Pose()
            mol_id = row["Molecule ID"]
            conf_num = 1
            res_set = pyrosetta.generate_nonstandard_residue_set(
                lig, params_list=[f"{path_to_conformers}/{mol_id}/{mol_id}.params"]
            )
            pyrosetta.pose_from_file(
                lig, res_set, f"{path_to_conformers}/{mol_id}/{mol_id}_{conf_num:04}.pdb"
            )
            molecule_atoms, target_atoms = alignment.auto_align_residue_to_residue(
                lig, lig.residue(lig_res_num), target_res
            )
            df.loc[i, "Molecule Atoms"] = "-".join(molecule_atoms)
            df.loc[i, "Target Atoms"] = "-".join(target_atoms)

    def split_alabels(name):
        if pd.isna(name):
            return None
        value = str(name).strip()
        if value == "":
            return None
        if value == "default":
            return ("CD2", "CZ2", "CZ3")
        return tuple(value.split("-"))

    df["Molecule Atoms"] = df["Molecule Atoms"].apply(split_alabels)
    df["Target Atoms"] = df["Target Atoms"].apply(split_alabels)

    before_rows = len(df)
    df = df[df["Molecule Atoms"].notnull() & df["Target Atoms"].notnull()].copy()
    if len(df) != before_rows:
        print(
            f"Dropped {before_rows - len(df)} rows from CSV due to missing Molecule/Target Atoms."
        )

    df.to_pickle(pkl_file_name, protocol=4)


def _find_existing_cluster(coords, clusters, rmsd_cutoff):
    for idx, cluster in enumerate(clusters):
        rmsd = dpu.ligand_rmsd(coords, cluster["coords"])
        if rmsd <= rmsd_cutoff:
            return idx
    return None


def setup_packer_task():
    from pyrosetta.rosetta.core.pack.task import TaskFactory, operation
    from pyrosetta.rosetta.protocols import minimization_packing as pack_min

    tf = TaskFactory()
    tf.push_back(operation.InitializeFromCommandline())
    tf.push_back(operation.IncludeCurrent())
    tf.push_back(operation.NoRepackDisulfides())
    tf.push_back(operation.RestrictToRepacking())
    packer = pack_min.PackRotamersMover()
    packer.task_factory(tf)
    return packer


def add_hbond_constraint(
    pose,
    lig_res_idx,
    lig_atom_name,
    target_res_idx,
    target_atom_name,
    dist_ideal=2.8,
    dist_sd=0.2,
):
    from pyrosetta.rosetta.core.scoring.constraints import AtomPairConstraint
    from pyrosetta.rosetta.core.scoring.func import HarmonicFunc
    from pyrosetta.rosetta.core.id import AtomID

    try:
        if not pose.residue(lig_res_idx).has(lig_atom_name):
            return
        if not pose.residue(target_res_idx).has(target_atom_name):
            return
        lig_atom_id = AtomID(
            pose.residue(lig_res_idx).atom_index(lig_atom_name), lig_res_idx
        )
        target_atom_id = AtomID(
            pose.residue(target_res_idx).atom_index(target_atom_name), target_res_idx
        )
        pose.add_constraint(
            AtomPairConstraint(
                lig_atom_id, target_atom_id, HarmonicFunc(float(dist_ideal), float(dist_sd))
            )
        )
    except Exception:
        pass


def add_hbond_constraint_to_water(
    pose,
    lig_res_idx,
    lig_atom_name,
    dist_ideal=2.8,
    dist_sd=0.3,
    capture_max=8.0,
):
    from pyrosetta.rosetta.core.scoring.constraints import AtomPairConstraint
    from pyrosetta.rosetta.core.scoring.func import HarmonicFunc
    from pyrosetta.rosetta.core.id import AtomID

    try:
        lig = pose.residue(lig_res_idx)
        if not lig.has(lig_atom_name):
            return
        lig_atom_idx = lig.atom_index(lig_atom_name)
        lig_xyz = lig.xyz(lig_atom_idx)
        best = None
        best_dist = None
        for resid in range(1, pose.total_residue() + 1):
            water = pose.residue(resid)
            if not water.is_water():
                continue
            for o_idx in range(1, water.natoms() + 1):
                if water.atom_type(o_idx).element() != "O":
                    continue
                d = lig_xyz.distance(water.xyz(o_idx))
                if best_dist is None or d < best_dist:
                    best_dist = d
                    best = (resid, o_idx)
        if best is None or best_dist is None or best_dist > float(capture_max):
            return
        wat_res_idx, wat_o_idx = best
        lig_atom_id = AtomID(lig_atom_idx, lig_res_idx)
        wat_atom_id = AtomID(wat_o_idx, wat_res_idx)
        pose.add_constraint(
            AtomPairConstraint(
                lig_atom_id, wat_atom_id, HarmonicFunc(float(dist_ideal), float(dist_sd))
            )
        )
    except Exception:
        pass


def auto_setup_water_constraints(pose, lig_res_idx, dist_cutoff=3.5):
    from pyrosetta.rosetta.core.scoring.constraints import AtomPairConstraint
    from pyrosetta.rosetta.core.scoring.func import HarmonicFunc
    from pyrosetta.rosetta.core.id import AtomID

    lig_res = pose.residue(lig_res_idx)
    water_indices = [
        i
        for i in range(1, pose.total_residue() + 1)
        if pose.residue(i).is_water()
        and pose.residue(i).nbr_atom_xyz().distance(lig_res.nbr_atom_xyz()) < 6.0
    ]
    for wat_res_idx in water_indices:
        wat_res = pose.residue(wat_res_idx)
        potential_acceptors, potential_donors = [], []
        for i in range(1, pose.total_residue() + 1):
            if i == wat_res_idx:
                continue
            curr_res = pose.residue(i)
            if (
                curr_res.nbr_atom_xyz().distance(wat_res.nbr_atom_xyz())
                > (dist_cutoff + 5.0)
            ):
                continue
            for atom_i in range(1, curr_res.natoms() + 1):
                dist = curr_res.xyz(atom_i).distance(wat_res.xyz("O"))
                if dist > dist_cutoff:
                    continue
                atom_name = curr_res.atom_name(atom_i).strip()
                is_lig = i == lig_res_idx
                if curr_res.atom_is_polar_hydrogen(atom_i):
                    potential_donors.append(
                        (dist - (0.5 if is_lig else 0.0), i, atom_name)
                    )
                elif curr_res.heavyatom_is_an_acceptor(atom_i):
                    potential_acceptors.append(
                        (dist - (0.5 if is_lig else 0.0), i, atom_name)
                    )
        potential_donors.sort()
        potential_acceptors.sort()
        if potential_donors:
            best = potential_donors[0]
            pose.add_constraint(
                AtomPairConstraint(
                    AtomID(wat_res.atom_index("O"), wat_res_idx),
                    AtomID(pose.residue(best[1]).atom_index(best[2]), best[1]),
                    HarmonicFunc(2.0, 0.2),
                )
            )
        if potential_acceptors:
            best = potential_acceptors[0]
            pose.add_constraint(
                AtomPairConstraint(
                    AtomID(wat_res.atom_index("H1"), wat_res_idx),
                    AtomID(pose.residue(best[1]).atom_index(best[2]), best[1]),
                    HarmonicFunc(2.0, 0.2),
                )
            )


def _passes_hbond_ideal_window(hbond_result, params):
    if not params.get("enforce_ideal_window", False):
        return True
    dist = hbond_result.get("distance", None)
    donor = hbond_result.get("donor_angle", None)
    acceptor = hbond_result.get("acceptor_angle", None)
    if dist is None or donor is None:
        return False
    if abs(dist - params["hbond_ideal"]) > params["distance_ideal_buffer"]:
        return False
    donor_floor = params["donor_ideal"] - params["donor_ideal_buffer"]
    if donor < donor_floor:
        return False
    if params.get("require_acceptor_ideal_window", False):
        if acceptor is None:
            return False
        acceptor_floor = params["acceptor_ideal"] - params["acceptor_ideal_buffer"]
        if acceptor < acceptor_floor:
            return False
    return True


def _passes_hbond_ideal_window_explicit(hbond_result, params):
    dist = hbond_result.get("distance", None)
    donor = hbond_result.get("donor_angle", None)
    acceptor = hbond_result.get("acceptor_angle", None)
    if dist is None or donor is None:
        return False
    if abs(dist - params["hbond_ideal"]) > params["distance_ideal_buffer"]:
        return False
    donor_floor = params["donor_ideal"] - params["donor_ideal_buffer"]
    if donor < donor_floor:
        return False
    if params.get("require_acceptor_ideal_window", False):
        if acceptor is None:
            return False
        acceptor_floor = params["acceptor_ideal"] - params["acceptor_ideal_buffer"]
        if acceptor < acceptor_floor:
            return False
    return True


def _water_diagnostics(pose, lig_res_idx, acceptor_atom_name):
    import numpy as np

    lig = pose.residue(lig_res_idx)
    acc_idx = dpu.atom_index_by_name(lig, acceptor_atom_name) if acceptor_atom_name else None
    if acc_idx is None:
        for i in range(1, lig.natoms() + 1):
            if lig.atom_type(i).element() in {"O", "N"}:
                acc_idx = i
                break
    if acc_idx is None:
        return (0, None)
    acc_xyz = dpu._xyz_to_np(lig.xyz(acc_idx))
    num_waters = 0
    nearest = None
    for resid in range(1, pose.total_residue() + 1):
        water = pose.residue(resid)
        if not water.is_water():
            continue
        num_waters += 1
        for o_idx in range(1, water.natoms() + 1):
            if water.atom_type(o_idx).element() != "O":
                continue
            o_xyz = dpu._xyz_to_np(water.xyz(o_idx))
            dist = float(np.linalg.norm(o_xyz - acc_xyz))
            if nearest is None or dist < nearest:
                nearest = dist
    return (num_waters, nearest)


def _closest_ligand_acceptor_to_any_water(pose, lig_res_idx):
    import numpy as np

    lig = pose.residue(lig_res_idx)
    acceptor_indices = []
    for i in range(1, lig.natoms() + 1):
        try:
            is_acceptor = lig.heavyatom_is_an_acceptor(i)
        except Exception:
            is_acceptor = False
        if not is_acceptor:
            continue
        if lig.atom_type(i).element() not in {"O", "N"}:
            continue
        acceptor_indices.append(i)
    if not acceptor_indices:
        return (None, None, None)

    best_atom = None
    best_dist = None
    best_water = None
    for acc_idx in acceptor_indices:
        acc_xyz = np.array(
            [float(lig.xyz(acc_idx).x), float(lig.xyz(acc_idx).y), float(lig.xyz(acc_idx).z)],
            dtype=float,
        )
        for resid in range(1, pose.total_residue() + 1):
            water = pose.residue(resid)
            if not water.is_water():
                continue
            for o_idx in range(1, water.natoms() + 1):
                if water.atom_type(o_idx).element() != "O":
                    continue
                o_xyz = np.array(
                    [
                        float(water.xyz(o_idx).x),
                        float(water.xyz(o_idx).y),
                        float(water.xyz(o_idx).z),
                    ],
                    dtype=float,
                )
                dist = float(np.linalg.norm(o_xyz - acc_xyz))
                if best_dist is None or dist < best_dist:
                    best_dist = dist
                    best_atom = lig.atom_name(acc_idx).strip()
                    best_water = resid
    return (best_atom, best_dist, best_water)


def align_to_residue_and_check_collision(
    pose,
    res,
    target_res_idx,
    path_to_conformers,
    df,
    pkl_file,
    jump_num,
    rotation,
    translation,
    upper_water_distance,
    lower_water_distance,
    backbone_clash_keep_sidechains,
    max_pass_score=-300,
    bin_width=1,
    vdw_modifier=0.7,
    include_sc=False,
    lig_res_num=1,
    output_dirs=None,
    rename_water_to_tp3=True,
    use_hbond_geometry_filter=True,
    hbond_distance_min=1.5,
    hbond_distance_max=3.5,
    hbond_distance_ideal=2.8,
    hbond_donor_angle_min=100.0,
    hbond_acceptor_angle_min=90.0,
    hbond_quality_min=0.25,
    use_closest_acceptor=True,
    hbond_constraint_weight=1.0,
    hbond_constraint_sd=0.3,
    hbond_constraint_capture_max=8.0,
    dynamic_water_pull_constraint=True,
    enforce_ideal_window=False,
    enforce_final_ideal_geometry=True,
    distance_ideal_buffer=0.5,
    donor_ideal=180.0,
    donor_ideal_buffer=25.0,
    acceptor_ideal=180.0,
    acceptor_ideal_buffer=30.0,
    require_acceptor_ideal_window=False,
    max_tries=30,
    debug_every=10,
    slow_min_threshold_sec=5.0,
    geometry_csv_path=None,
    cluster_enabled=True,
    cluster_rmsd_cutoff=0.75,
):
    import pyrosetta.rosetta.protocols.grafting as graft
    import pyrosetta.rosetta.protocols.rigid as rigid_moves
    import pyrosetta.rosetta.core.scoring as scoring

    packer = setup_packer_task()

    sf_all = pyrosetta.get_fa_scorefxn()
    sf_cst = pyrosetta.get_fa_scorefxn()
    sf_cst.set_weight(scoring.atom_pair_constraint, float(hbond_constraint_weight))
    min_mover = pyrosetta.rosetta.protocols.minimization_packing.MinMover()
    mm = pyrosetta.MoveMap()
    mm.set_jump(True)
    min_mover.movemap(mm)
    min_mover.score_function(sf_cst)

    t0 = time.time()
    total_confs = 0
    total_geometry_accepted = 0
    total_pass_score = 0
    total_cluster_kept = 0
    geometry_rows = []
    params = {
        "enforce_ideal_window": enforce_ideal_window,
        "hbond_ideal": hbond_distance_ideal,
        "distance_ideal_buffer": distance_ideal_buffer,
        "donor_ideal": donor_ideal,
        "donor_ideal_buffer": donor_ideal_buffer,
        "acceptor_ideal": acceptor_ideal,
        "acceptor_ideal_buffer": acceptor_ideal_buffer,
        "require_acceptor_ideal_window": require_acceptor_ideal_window,
    }

    alignto_pose = pose
    clusters = []

    loop_include_sidechain_pose = pose.clone()
    keep_sidechain = [int(x) for x in backbone_clash_keep_sidechains]
    for i in range(1, loop_include_sidechain_pose.total_residue() + 1):
        if i not in keep_sidechain:
            pyrosetta.toolbox.mutate_residue(loop_include_sidechain_pose, i, "G")

    backbone_grid = collision_check.CollisionGrid(
        loop_include_sidechain_pose,
        bin_width=bin_width,
        vdw_modifier=vdw_modifier,
        include_sc=True,
    )

    for pose_info in conformer_prep.yield_ligand_poses(
        df=df,
        path_to_conformers=path_to_conformers,
        post_accepted_conformers=False,
        ligand_residue=lig_res_num,
    ):
        if not pose_info:
            logger.warning("Conformer info missing; skipping.")
            continue

        conf = pose_info
        if total_confs == 0 or (total_confs + 1) % max(1, int(debug_every)) == 0:
            logger.info(
                "Processing conformer %d (conf_num=%s). geometry_pass=%d score_pass=%d clustered=%d",
                total_confs + 1,
                getattr(conf, "conf_num", "NA"),
                total_geometry_accepted,
                total_pass_score,
                total_cluster_kept,
            )
        conf.align_to_target(res)

        molecule_atoms = None
        target_atoms = None
        if hasattr(conf, "molecule_atoms") and hasattr(conf, "target_atoms"):
            molecule_atoms = conf.molecule_atoms
            target_atoms = conf.target_atoms
        elif hasattr(conf, "lig_atoms") and hasattr(conf, "target_atoms"):
            molecule_atoms = conf.lig_atoms
            target_atoms = conf.target_atoms
        elif hasattr(conf, "lig_aid") and hasattr(conf, "t_aid"):
            molecule_atoms = conf.lig_aid
            target_atoms = conf.t_aid
        if molecule_atoms is None or target_atoms is None or len(molecule_atoms) < 1:
            logger.warning("Conformer missing alignment atom labels; skipping.")
            total_confs += 1
            continue

        location = len(alignto_pose.chain_sequence(1))
        new_pose = graft.insert_pose_into_pose(alignto_pose, conf.pose, location)
        ligand_res_index = location + 1

        keep_candidate = False
        accepted_try_idx = None
        last_hbond_result = None
        strict_ok = False
        copy_pose = None
        acceptor_name = molecule_atoms[0]
        neighbor_names = list(molecule_atoms[1:3])

        count = 0
        while not keep_candidate and count < int(max_tries):
            copy_pose = new_pose.clone()
            pert_mover = rigid_moves.RigidBodyPerturbMover(jump_num, rotation, translation)
            pert_mover.apply(copy_pose)
            for atom_id in range(1, copy_pose.residue(ligand_res_index).natoms() + 1):
                atom_coords = copy_pose.residue(ligand_res_index).xyz(atom_id)
                conf.pose.residue(1).set_xyz(atom_id, atom_coords)

            does_collide = conf.check_collision(backbone_grid)
            if not does_collide:
                acceptor_name = molecule_atoms[0]
                neighbor_names = list(molecule_atoms[1:3])
                if use_closest_acceptor:
                    closest_atom, _, _ = _closest_ligand_acceptor_to_any_water(
                        copy_pose, ligand_res_index
                    )
                    if closest_atom is not None:
                        acceptor_name = closest_atom
                    neighbor_names = []

                if (
                    (not use_closest_acceptor)
                    and target_res_idx is not None
                    and target_res_idx > 0
                    and len(target_atoms) > 0
                ):
                    add_hbond_constraint(
                        copy_pose,
                        ligand_res_index,
                        acceptor_name,
                        target_res_idx,
                        target_atoms[0],
                        hbond_distance_ideal,
                    )
                if use_closest_acceptor and dynamic_water_pull_constraint:
                    add_hbond_constraint_to_water(
                        copy_pose,
                        ligand_res_index,
                        acceptor_name,
                        dist_ideal=hbond_distance_ideal,
                        dist_sd=hbond_constraint_sd,
                        capture_max=hbond_constraint_capture_max,
                    )
                auto_setup_water_constraints(copy_pose, ligand_res_index)
                t_min0 = time.time()
                min_mover.apply(copy_pose)
                min_dt = time.time() - t_min0
                if min_dt > float(slow_min_threshold_sec):
                    logger.info(
                        "Slow minimization: conformer %d (conf_num=%s), try %d/%d took %.2fs",
                        total_confs + 1,
                        getattr(conf, "conf_num", "NA"),
                        count + 1,
                        int(max_tries),
                        min_dt,
                    )

                hbond_result = dpu.evaluate_hbond_geometry(
                    copy_pose,
                    ligand_res_index,
                    acceptor_atom_name=acceptor_name,
                    neighbor_atom_names=neighbor_names,
                    distance_min=hbond_distance_min if use_hbond_geometry_filter else lower_water_distance,
                    distance_max=hbond_distance_max if use_hbond_geometry_filter else upper_water_distance,
                    distance_ideal=hbond_distance_ideal,
                    donor_angle_min=hbond_donor_angle_min,
                    acceptor_angle_min=hbond_acceptor_angle_min,
                    quality_min=hbond_quality_min if use_hbond_geometry_filter else 0.0,
                )
                last_hbond_result = hbond_result
                strict_ok = _passes_hbond_ideal_window(hbond_result, params)
                if (hbond_result["passed"] and strict_ok) or (not use_hbond_geometry_filter):
                    keep_candidate = True
                    accepted_try_idx = count + 1
            count += 1

        if not keep_candidate or copy_pose is None:
            num_waters, nearest_water_dist = _water_diagnostics(
                new_pose, ligand_res_index, molecule_atoms[0]
            )
            logger.info(
                "Conformer %d (conf_num=%s) failed after %d tries; quality=%s waters=%d nearest_water_O=%.3f strict=%s",
                total_confs + 1,
                getattr(conf, "conf_num", "NA"),
                int(max_tries),
                (
                    f"{last_hbond_result.get('quality', None):.3f}"
                    if last_hbond_result and last_hbond_result.get("quality", None) is not None
                    else "None"
                ),
                num_waters,
                nearest_water_dist if nearest_water_dist is not None else -1.0,
                strict_ok,
            )
            geometry_rows.append(
                {
                    "conf_idx": total_confs + 1,
                    "conf_num": getattr(conf, "conf_num", "NA"),
                    "accepted": False,
                    "accepted_try": accepted_try_idx,
                    "passed_score": False,
                    "saved_cluster": False,
                    "score": None,
                    "distance": None if last_hbond_result is None else last_hbond_result.get("distance", None),
                    "donor_angle": None if last_hbond_result is None else last_hbond_result.get("donor_angle", None),
                    "acceptor_angle": None if last_hbond_result is None else last_hbond_result.get("acceptor_angle", None),
                    "quality": None if last_hbond_result is None else last_hbond_result.get("quality", None),
                    "water_residue": None if last_hbond_result is None else last_hbond_result.get("water_residue", None),
                    "strict_window_passed": strict_ok,
                    "output_pdb": None,
                }
            )
            total_confs += 1
            continue
        total_geometry_accepted += 1

        if output_dirs:
            pass_idx = output_dirs["current_pass"]
            rotated_dir = output_dirs["rotated_dirs"][pass_idx]
            rotated_path = os.path.join(rotated_dir, f"rotated_{total_confs}.pdb")
        else:
            rotated_path = os.path.join("rotated", f"rotated_{total_confs}.pdb")
        dpu.dump_pose_pdb(copy_pose, rotated_path, rename_water=rename_water_to_tp3)

        packer.apply(copy_pose)
        for atom_id in range(1, copy_pose.residue(ligand_res_index).natoms() + 1):
            atom_coords = copy_pose.residue(ligand_res_index).xyz(atom_id)
            conf.pose.residue(1).set_xyz(atom_id, atom_coords)

        remove_ligand_pose = copy_pose.clone()
        remove_ligand_pose.delete_residue_slow(ligand_res_index)
        grid = collision_check.CollisionGrid(
            remove_ligand_pose,
            bin_width=bin_width,
            vdw_modifier=vdw_modifier,
            include_sc=include_sc,
        )
        does_collide = conf.check_collision(grid)
        if does_collide:
            print("Conformer failed final collision check; not saving.")
            geometry_rows.append(
                {
                    "conf_idx": total_confs + 1,
                    "conf_num": getattr(conf, "conf_num", "NA"),
                    "accepted": True,
                    "accepted_try": accepted_try_idx,
                    "passed_score": False,
                    "saved_cluster": False,
                    "score": None,
                    "distance": None,
                    "donor_angle": None,
                    "acceptor_angle": None,
                    "quality": None,
                    "water_residue": None,
                    "strict_window_passed": strict_ok,
                    "postpack_geometry_passed": False,
                    "postpack_ideal_passed": False,
                    "output_pdb": None,
                }
            )
            total_confs += 1
            continue

        score = sf_all(copy_pose)
        postpack_hbond_result = dpu.evaluate_hbond_geometry(
            copy_pose,
            ligand_res_index,
            acceptor_atom_name=acceptor_name,
            neighbor_atom_names=neighbor_names,
            distance_min=hbond_distance_min,
            distance_max=hbond_distance_max,
            distance_ideal=hbond_distance_ideal,
            donor_angle_min=hbond_donor_angle_min,
            acceptor_angle_min=hbond_acceptor_angle_min,
            quality_min=hbond_quality_min,
        )
        postpack_pass = bool(postpack_hbond_result.get("passed", False))
        postpack_strict_ok = (
            _passes_hbond_ideal_window_explicit(postpack_hbond_result, params)
            if enforce_final_ideal_geometry
            else True
        )
        if use_hbond_geometry_filter and not (postpack_pass and postpack_strict_ok):
            logger.info(
                "Post-pack geometry reject: conformer %d (conf_num=%s) passed=%s strict=%s",
                total_confs + 1,
                getattr(conf, "conf_num", "NA"),
                postpack_pass,
                postpack_strict_ok,
            )
            geometry_rows.append(
                {
                    "conf_idx": total_confs + 1,
                    "conf_num": getattr(conf, "conf_num", "NA"),
                    "accepted": True,
                    "accepted_try": accepted_try_idx,
                    "passed_score": False,
                    "saved_cluster": False,
                    "score": score,
                    "distance": postpack_hbond_result.get("distance", None),
                    "donor_angle": postpack_hbond_result.get("donor_angle", None),
                    "acceptor_angle": postpack_hbond_result.get("acceptor_angle", None),
                    "quality": postpack_hbond_result.get("quality", None),
                    "water_residue": postpack_hbond_result.get("water_residue", None),
                    "strict_window_passed": _passes_hbond_ideal_window(postpack_hbond_result, params),
                    "postpack_geometry_passed": postpack_pass,
                    "postpack_ideal_passed": postpack_strict_ok,
                    "output_pdb": None,
                }
            )
            total_confs += 1
            continue

        if score >= max_pass_score:
            print("Score too high; not saving this conformer.")
            geometry_rows.append(
                {
                    "conf_idx": total_confs + 1,
                    "conf_num": getattr(conf, "conf_num", "NA"),
                    "accepted": True,
                    "accepted_try": accepted_try_idx,
                    "passed_score": False,
                    "saved_cluster": False,
                    "score": score,
                    "distance": postpack_hbond_result.get("distance", None),
                    "donor_angle": postpack_hbond_result.get("donor_angle", None),
                    "acceptor_angle": postpack_hbond_result.get("acceptor_angle", None),
                    "quality": postpack_hbond_result.get("quality", None),
                    "water_residue": postpack_hbond_result.get("water_residue", None),
                    "strict_window_passed": _passes_hbond_ideal_window(postpack_hbond_result, params),
                    "postpack_geometry_passed": postpack_pass,
                    "postpack_ideal_passed": postpack_strict_ok,
                    "output_pdb": None,
                }
            )
            total_confs += 1
            continue

        total_pass_score += 1

        coords = dpu.ligand_heavy_atom_coords(copy_pose, ligand_res_index)
        if cluster_enabled:
            cluster_idx = _find_existing_cluster(coords, clusters, cluster_rmsd_cutoff)
        else:
            cluster_idx = None

        if cluster_idx is None:
            cluster_id = len(clusters) + 1
            if output_dirs:
                pass_idx = output_dirs["current_pass"]
                repacked_dir = output_dirs["pass_score_repacked_dirs"][pass_idx]
                out_path = os.path.join(
                    repacked_dir, f"repacked_cluster{cluster_id:04}.pdb"
                )
            else:
                out_path = os.path.join("pass_score_repacked", f"repacked_cluster{cluster_id:04}.pdb")
            dpu.dump_pose_pdb(copy_pose, out_path, rename_water=rename_water_to_tp3)
            clusters.append({"coords": coords, "score": score, "path": out_path, "conf_num": conf.conf_num})
            total_cluster_kept += 1
            saved_cluster = True
        else:
            old = clusters[cluster_idx]
            if score < old["score"]:
                dpu.dump_pose_pdb(copy_pose, old["path"], rename_water=rename_water_to_tp3)
                old["coords"] = coords
                old["score"] = score
                old["conf_num"] = conf.conf_num
                print(f"Cluster {cluster_idx + 1}: replaced representative with improved score.")
            else:
                print(f"Cluster {cluster_idx + 1}: skipped near-duplicate pose.")
            saved_cluster = False

        geometry_rows.append(
            {
                "conf_idx": total_confs + 1,
                "conf_num": getattr(conf, "conf_num", "NA"),
                "accepted": True,
                "accepted_try": accepted_try_idx,
                "passed_score": True,
                "saved_cluster": saved_cluster,
                "score": score,
                "distance": postpack_hbond_result.get("distance", None),
                "donor_angle": postpack_hbond_result.get("donor_angle", None),
                "acceptor_angle": postpack_hbond_result.get("acceptor_angle", None),
                "quality": postpack_hbond_result.get("quality", None),
                "water_residue": postpack_hbond_result.get("water_residue", None),
                "strict_window_passed": _passes_hbond_ideal_window(postpack_hbond_result, params),
                "postpack_geometry_passed": postpack_pass,
                "postpack_ideal_passed": postpack_strict_ok,
                "output_pdb": out_path if cluster_idx is None else None,
            }
        )

        total_confs += 1

    if geometry_csv_path:
        pd.DataFrame(geometry_rows).to_csv(geometry_csv_path, index=False)
        logger.info("Wrote H-bond geometry CSV: %s (%d rows)", geometry_csv_path, len(geometry_rows))

    print(f"\n\n---Output, {pkl_file}---")
    print(f"\nNumber of Conformers: {total_confs}")
    print(f"Number of Conformers Passing Initial Geometry: {total_geometry_accepted}")
    print(f"Conformers that passed score cutoff: {total_pass_score}")
    print(f"Cluster representatives kept: {total_cluster_kept if cluster_enabled else 'clustering disabled'}")
    print(
        f"Proportion Passing Initial Geometry: "
        f"{total_geometry_accepted/total_confs if total_confs else 0}"
    )
    tf_end = time.time()
    print(f"\nTime taken: {(tf_end - t0)/60:.2f} minutes")
    print(f"Conformers per minute: {total_confs/(tf_end - t0)*60 if (tf_end - t0) > 0 else 0:.2f}")
    return {
        "total_conformers": total_confs,
        "accepted_conformers": total_geometry_accepted,
        "pass_score_conformers": total_pass_score,
        "cluster_representatives": total_cluster_kept if cluster_enabled else total_pass_score,
        "cluster_enabled": bool(cluster_enabled),
    }


def aggregate_pass_score_repacked(
    pass_score_repacked_dirs, num_passes, output_base=None, final_dir_name="clustered_final"
):
    """
    Aggregates all pass_score_repacked directories into one final directory.
    """
    if output_base:
        final_dir = os.path.join(output_base, final_dir_name)
    else:
        final_dir = os.path.join(os.getcwd(), final_dir_name)

    os.makedirs(final_dir, exist_ok=True)
    print(f"\nCreated final aggregation directory: {final_dir}")

    for pass_idx, source_dir in enumerate(pass_score_repacked_dirs, start=1):
        if not os.path.isdir(source_dir):
            print(f"Source directory {source_dir} does not exist. Skipping.")
            continue

        for file_name in os.listdir(source_dir):
            if file_name.startswith("repacked") and file_name.endswith(".pdb"):
                src_path = os.path.join(source_dir, file_name)
                new_file_name = f"pass{pass_idx}_{file_name}"
                dest_path = os.path.join(final_dir, new_file_name)
                try:
                    shutil.copyfile(src_path, dest_path)
                    print(f"Copied {src_path} to {dest_path}")
                except Exception as e:
                    print(f"Failed to copy {src_path} to {dest_path}: {e}")

    print(f"All pass_score_repacked files have been aggregated into {final_dir}")
    return final_dir


def write_summary_report(output_base, seq_name, mode, pass_summaries, final_dir):
    final_unique_clustered_docks = 0
    if os.path.isdir(final_dir):
        final_unique_clustered_docks = len(
            [
                name
                for name in os.listdir(final_dir)
                if name.startswith("pass") and name.endswith(".pdb")
            ]
        )

    report = {
        "mode": mode,
        "sequence_name": seq_name,
        "num_passes": len(pass_summaries),
        "per_pass": pass_summaries,
        "totals": {
            "total_conformers": sum(item["total_conformers"] for item in pass_summaries),
            "accepted_conformers": sum(item["accepted_conformers"] for item in pass_summaries),
            "pass_score_conformers": sum(item["pass_score_conformers"] for item in pass_summaries),
            "cluster_representatives": sum(
                item["cluster_representatives"] for item in pass_summaries
            ),
            "final_unique_clustered_docks": final_unique_clustered_docks,
        },
        "final_clustered_docks_dir": final_dir,
    }

    report_path = os.path.join(output_base, f"summary_{seq_name}.json")
    with open(report_path, "w", encoding="utf-8") as handle:
        json.dump(report, handle, indent=2)

    print(f"\nSummary report written: {report_path}")
    print(
        "Final unique clustered docks (water-geometry + score + clustering): "
        f"{report['totals']['final_unique_clustered_docks']}"
    )
    return report_path


def main(argv):
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        description=__doc__
    )
    parser.add_argument("config_file", help="Your config file", default="config.txt", nargs="?")
    parser.add_argument(
        "array_index",
        nargs="?",
        default=0,
        type=int,
        help="SLURM array index (selects row from CSV, default=0)",
    )
    if len(argv) == 0:
        parser.print_help()
        return
    args = parser.parse_args(argv)
    array_index = args.array_index

    config = ConfigParser()
    with open(args.config_file, "r", encoding="utf-8-sig") as handle:
        config.read_file(handle)
    default = config["DEFAULT"]
    spec = config["grade_conformers"]

    # Load sequence-specific config
    seq_section = config["SEQUENCE_DOCKING"] if "SEQUENCE_DOCKING" in config else {}
    multiple = config["MULTIPLE_PASSES"] if "MULTIPLE_PASSES" in config else {}

    # Load sequence from CSV
    csv_path = seq_section.get("SequenceCSV", None)
    if not csv_path:
        raise ValueError("SequenceCSV must be specified in [SEQUENCE_DOCKING] section")

    positions_str = seq_section.get("ThreadingPositions", None)
    if not positions_str:
        raise ValueError("ThreadingPositions must be specified in [SEQUENCE_DOCKING] section")

    threading_positions = [int(x) for x in positions_str.split()]
    seq_name, signature = load_sequence_from_csv(csv_path, array_index)
    validate_signature(signature, threading_positions)

    logger.info(f"Threading signature '{signature}' onto positions: {threading_positions}")

    script_dir = os.path.dirname(os.path.abspath(__file__))
    legacy_dir = os.path.normpath(os.path.join(script_dir, "..", "legacy"))
    for path in [script_dir, legacy_dir]:
        if path not in sys.path:
            sys.path.insert(0, path)

    pyro_path = default.get("PathToPyRosetta", "").strip()
    if pyro_path:
        sys.path.append(pyro_path)
    auto = default.getboolean("AutoGenerateAlignment")

    global pyrosetta, Pose, alignment, conformer_prep, collision_check
    import pyrosetta
    from pyrosetta.rosetta.core.pose import Pose
    import alignment
    import conformer_prep
    import collision_check

    pyrosetta.init("-mute all")
    params_list = default["ParamsList"]

    print("Reading in Pre and Post PDBs")
    if params_list.strip():
        pre_pose = Pose()
        res_set = pyrosetta.generate_nonstandard_residue_set(
            pre_pose, params_list=params_list.split(" ")
        )
        pyrosetta.pose_from_file(pre_pose, res_set, default["PrePDBFileName"])
        post_pose = Pose()
        res_set = pyrosetta.generate_nonstandard_residue_set(
            post_pose, params_list=params_list.split(" ")
        )
        pyrosetta.pose_from_file(post_pose, res_set, default["PostPDBFileName"])
    else:
        pre_pose = pyrosetta.pose_from_pdb(default["PrePDBFileName"])
        post_pose = pyrosetta.pose_from_pdb(default["PostPDBFileName"])

    # Thread the sequence onto specified positions
    logger.info("Threading sequence onto pose...")
    for pos, aa in zip(threading_positions, signature):
        logger.info(f"  Position {pos} -> {aa}")
        pyrosetta.toolbox.mutate_residue(post_pose, pos, aa.upper())

    rename_water_to_tp3 = dpu.cfg_getbool(config, "grade_conformers", "RenameWaterToTP3", True)
    post_mutate_path = f"post_mutate_{seq_name}.pdb"
    dpu.dump_pose_pdb(post_pose, post_mutate_path, rename_water=rename_water_to_tp3)
    logger.info(f"Saved threaded pose: {post_mutate_path}")

    target_res_num = _cfg_int(default, "ResidueNumber", 1)
    chain_letter = default["ChainLetter"]
    pre_target_idx = pre_pose.pdb_info().pdb2pose(chain_letter, target_res_num)
    post_target_idx = post_pose.pdb_info().pdb2pose(chain_letter, target_res_num)
    if pre_target_idx <= 0 or pre_target_idx > pre_pose.total_residue():
        raise ValueError(
            f"Could not map target residue {chain_letter}{target_res_num} into pre pose. "
            f"pre_pose pdb2pose={pre_target_idx}, post_pose pdb2pose={post_target_idx}, "
            f"pre_pose.total_residue={pre_pose.total_residue()}"
        )
    res = pre_pose.residue(pre_target_idx)
    target_idx = post_target_idx if post_target_idx > 0 else None

    path_to_conformers = dpu.cfg_get(config, "create_table", "PathToConformers", default["PathToConformers"])
    csv_file_name = dpu.cfg_get(config, "create_table", "CSVFileName", default["CSVFileName"])
    pkl_file_name = dpu.cfg_get(config, "create_table", "PKLFileName", default["PKLFileName"])
    if not str(pkl_file_name).strip():
        pkl_file_name = None

    auto_prepare = dpu.cfg_getbool(config, "create_table", "AutoPrepareFromSDF", True)
    if auto_prepare:
        dpu.ensure_table_ready(args.config_file, csv_file_name)

    print(f"PKL File Name: {pkl_file_name}")
    bin_width = _cfg_float(spec, "BinWidth", 1.0)
    vdw_modifier = _cfg_float(spec, "VDW_Modifier", 0.7)
    include_sc = _cfg_bool(spec, "IncludeSC", False)
    lig_res_num = _cfg_int(default, "LigandResidueNumber", 1)
    jump_num = _cfg_int(spec, "JumpNum", 2)
    rotation = _cfg_float(spec, "Rotation", 25.0)
    translation = _cfg_float(spec, "Translation", 0.5)
    upper_water_distance = _cfg_float(spec, "UpperWaterDistance", 3.5)
    lower_water_distance = _cfg_float(spec, "LowerWaterDistance", 1.5)
    backbone_clash_keep_sidechains = spec["BackboneClashKeepSidechains"].split()
    max_pass_score = _cfg_float(spec, "MaxScore", -300.0)

    use_hbond_geometry_filter = _cfg_bool(spec, "EnableHBondGeometryFilter", True)
    hbond_distance_ideal = _cfg_float(spec, "HBondDistanceIdeal", 2.8)
    distance_ideal_buffer = _cfg_float(spec, "HBondDistanceIdealBuffer", 0.5)
    if "HBondDistanceMin" in spec:
        hbond_distance_min = _cfg_float(spec, "HBondDistanceMin", hbond_distance_ideal - distance_ideal_buffer)
    else:
        hbond_distance_min = max(0.0, hbond_distance_ideal - distance_ideal_buffer)
    if "HBondDistanceMax" in spec:
        hbond_distance_max = _cfg_float(spec, "HBondDistanceMax", hbond_distance_ideal + distance_ideal_buffer)
    else:
        hbond_distance_max = hbond_distance_ideal + distance_ideal_buffer
    hbond_donor_angle_min = _cfg_float(spec, "HBondDonorAngleMin", 100.0)
    hbond_acceptor_angle_min = _cfg_float(spec, "HBondAcceptorAngleMin", 90.0)
    raw_quality_min = _cfg_clean(spec.get("HBondQualityMin", ""))
    hbond_quality_min = float(raw_quality_min) if raw_quality_min else 0.0

    use_closest_acceptor = _cfg_bool(spec, "UseClosestLigandAcceptor", True)
    hbond_constraint_weight = _cfg_float(spec, "HBondConstraintWeight", 1.0)
    hbond_constraint_sd = _cfg_float(spec, "HBondConstraintSD", 0.3)
    hbond_constraint_capture_max = _cfg_float(spec, "HBondConstraintCaptureMax", 8.0)
    dynamic_water_pull_constraint = _cfg_bool(spec, "EnableDynamicWaterPullConstraint", True)
    enforce_ideal_window = _cfg_bool(spec, "EnforceHBondIdealWindow", False)
    enforce_final_ideal_geometry = _cfg_bool(spec, "EnforceFinalIdealGeometry", True)
    donor_ideal = _cfg_float(spec, "HBondDonorAngleIdeal", 180.0)
    donor_ideal_buffer = _cfg_float(spec, "HBondDonorAngleBuffer", 25.0)
    acceptor_ideal = _cfg_float(spec, "HBondAcceptorAngleIdeal", 180.0)
    acceptor_ideal_buffer = _cfg_float(spec, "HBondAcceptorAngleBuffer", 30.0)
    require_acceptor_ideal_window = _cfg_bool(spec, "RequireAcceptorIdealWindow", False)
    max_tries = _cfg_int(spec, "MaxPerturbTries", 30)
    debug_every = _cfg_int(spec, "DebugEveryN", 10)
    slow_min_threshold_sec = _cfg_float(spec, "SlowMinimizationSeconds", 5.0)

    cluster_enabled = dpu.cfg_getbool(config, "grade_conformers", "EnablePoseClustering", True)
    cluster_rmsd_cutoff = float(
        dpu.cfg_get(config, "grade_conformers", "ClusterRMSDCutoff", "0.75")
    )

    print("Attempting to read .pkl file")
    try:
        df = pd.read_pickle(pkl_file_name)
        print(f"Successfully loaded {pkl_file_name}")
    except FileNotFoundError:
        print(f".pkl file {pkl_file_name} not found, generating one instead")
        csv_to_df_pkl(csv_file_name, pkl_file_name, auto, path_to_conformers, pre_pose, res, lig_res_num)
        df = pd.read_pickle(pkl_file_name)
        print(f"Generated and loaded {pkl_file_name}")

    num_passes = multiple.getint("NumPasses", fallback=1)

    # Option C: {OutputDirBase}/sequences/{seq_name}/
    base_output_dir = multiple.get("OutputDirBase", fallback=os.getcwd())
    output_base = os.path.join(base_output_dir, "sequences", seq_name)
    os.makedirs(output_base, exist_ok=True)
    logger.info(f"Sequence output directory: {output_base}")

    rotated_dirs = []
    pass_score_repacked_dirs = []

    for pass_idx in range(1, num_passes + 1):
        rotated_dir = os.path.join(output_base, f"rotated_pass{pass_idx}")
        pass_score_repacked_dir = os.path.join(output_base, f"pass_score_repacked_pass{pass_idx}")
        os.makedirs(rotated_dir, exist_ok=True)
        os.makedirs(pass_score_repacked_dir, exist_ok=True)
        rotated_dirs.append(rotated_dir)
        pass_score_repacked_dirs.append(pass_score_repacked_dir)

    output_dirs = {
        "current_pass": None,
        "rotated_dirs": rotated_dirs,
        "pass_score_repacked_dirs": pass_score_repacked_dirs,
    }

    combined_df = pd.DataFrame()
    pass_summaries = []
    for pass_idx in range(1, num_passes + 1):
        print(f"\n--- Starting Pass {pass_idx} for sequence '{seq_name}' ---")
        output_dirs["current_pass"] = pass_idx - 1
        pass_stats = align_to_residue_and_check_collision(
            pose=post_pose,
            res=res,
            target_res_idx=target_idx,
            path_to_conformers=path_to_conformers,
            df=df,
            pkl_file=pkl_file_name,
            jump_num=jump_num,
            rotation=rotation,
            translation=translation,
            upper_water_distance=upper_water_distance,
            lower_water_distance=lower_water_distance,
            backbone_clash_keep_sidechains=backbone_clash_keep_sidechains,
            max_pass_score=max_pass_score,
            bin_width=bin_width,
            vdw_modifier=vdw_modifier,
            include_sc=include_sc,
            lig_res_num=lig_res_num,
            output_dirs=output_dirs,
            rename_water_to_tp3=rename_water_to_tp3,
            use_hbond_geometry_filter=use_hbond_geometry_filter,
            hbond_distance_min=hbond_distance_min,
            hbond_distance_max=hbond_distance_max,
            hbond_distance_ideal=hbond_distance_ideal,
            hbond_donor_angle_min=hbond_donor_angle_min,
            hbond_acceptor_angle_min=hbond_acceptor_angle_min,
            hbond_quality_min=hbond_quality_min,
            use_closest_acceptor=use_closest_acceptor,
            hbond_constraint_weight=hbond_constraint_weight,
            hbond_constraint_sd=hbond_constraint_sd,
            hbond_constraint_capture_max=hbond_constraint_capture_max,
            dynamic_water_pull_constraint=dynamic_water_pull_constraint,
            enforce_ideal_window=enforce_ideal_window,
            enforce_final_ideal_geometry=enforce_final_ideal_geometry,
            distance_ideal_buffer=distance_ideal_buffer,
            donor_ideal=donor_ideal,
            donor_ideal_buffer=donor_ideal_buffer,
            acceptor_ideal=acceptor_ideal,
            acceptor_ideal_buffer=acceptor_ideal_buffer,
            require_acceptor_ideal_window=require_acceptor_ideal_window,
            max_tries=max_tries,
            debug_every=debug_every,
            slow_min_threshold_sec=slow_min_threshold_sec,
            geometry_csv_path=os.path.join(
                output_base,
                f"hbond_geometry_pass{pass_idx}.csv",
            ),
            cluster_enabled=cluster_enabled,
            cluster_rmsd_cutoff=cluster_rmsd_cutoff,
        )
        pass_stats["pass_index"] = pass_idx
        pass_summaries.append(pass_stats)

    final_dir = aggregate_pass_score_repacked(
        pass_score_repacked_dirs,
        num_passes,
        output_base=output_base,
        final_dir_name="clustered_final",
    )
    write_summary_report(output_base, seq_name, "sequence", pass_summaries, final_dir)

    print(f"\n{'='*80}")
    print(f"SEQUENCE '{seq_name}' DOCKING COMPLETE")
    print(f"{'='*80}")
    print(f"Signature: {signature}")
    print(f"Positions: {threading_positions}")
    print(f"Output: {output_base}")
    print(f"Clustered docks: {final_dir}")


if __name__ == "__main__":
    main(sys.argv[1:])
